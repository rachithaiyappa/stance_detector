{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b939eda1",
   "metadata": {},
   "source": [
    "# This notebook shows how to run flant5-xxl on the prompts and get the needed outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f31e6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stance_detector.flant5_runner import FlanT5Runner\n",
    "import yaml\n",
    "import pprint as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "069ccb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '0GB', 1: '0GB', 2: '0GB', 3: '0GB', 4: '0GB', 5: '0GB', 6: '0GB', 7: '80GB'}\n"
     ]
    }
   ],
   "source": [
    "config_path = \"../config.yaml\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "max_memory_mapping = config[\"max_memory_mapping\"]\n",
    "print(max_memory_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load flant5\n",
    "model_name = \"google/flan-t5-xxl\"\n",
    "tokenizer_cache = \"/home/racball/flan-t5-xxl--tokeniser\"\n",
    "model_cache = \"/home/racball/models--flan-t5-xxl\"\n",
    "device_map = \"sequential\"\n",
    "cache_dir= \"/home/racball/flan-t5-xxl--tokeniser\"\n",
    "\n",
    "runner = FlanT5Runner(\n",
    "    model_name=model_name,\n",
    "    tokenizer_cache=tokenizer_cache,\n",
    "    model_cache=model_cache,\n",
    "    device_map=device_map,\n",
    "    max_memory=max_memory_mapping,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b8f1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-14 14:35:42,716 - stance_detector.flant5_runner - INFO - Loaded 1 records from ../data/semeval_taskA_targetAtheism_prompt1_instruction1_prompts_free.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/nobackup/racball/github/stance_detector/.venv/lib/python3.7/site-packages/transformers/generation_utils.py:1301: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-14 14:35:47,346 - stance_detector.flant5_runner - INFO - Saved results to ../data/semeval_taskA_targetAtheism_prompt1_instruction1_prompts_free--output.pkl\n",
      "2025-05-14 14:35:47,347 - stance_detector.flant5_runner - INFO - Processed 1 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_cf = runner.run_inference(input_path=\"../data/semeval_taskA_targetAtheism_prompt1_instruction1_prompts_free.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5283ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Target</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>label</th>\n",
       "      <th>class_tokens</th>\n",
       "      <th>generated_token</th>\n",
       "      <th>generated_out_tokens_log_prob</th>\n",
       "      <th>generated_overall_log_prob</th>\n",
       "      <th>class_token_log_probs</th>\n",
       "      <th>class_token_log_probs_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>He who exalts himself shall      be humbled; a...</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>Your response to the question should be either...</td>\n",
       "      <td>1_free--1</td>\n",
       "      <td>[Positive, Negative, Neutral, Positive., Negat...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>{'neutral': -0.7013075351715088, '&lt;/s&gt;': -2.12...</td>\n",
       "      <td>-0.701329</td>\n",
       "      <td>[{'Positive': -6.235310077667236, '&lt;/s&gt;': -2.1...</td>\n",
       "      <td>[-6.235331297146331, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID   Target                                              Tweet   Stance  \\\n",
       "0  10001  Atheism  He who exalts himself shall      be humbled; a...  AGAINST   \n",
       "\n",
       "                                              Prompt      label  \\\n",
       "0  Your response to the question should be either...  1_free--1   \n",
       "\n",
       "                                        class_tokens generated_token  \\\n",
       "0  [Positive, Negative, Neutral, Positive., Negat...         neutral   \n",
       "\n",
       "                       generated_out_tokens_log_prob  \\\n",
       "0  {'neutral': -0.7013075351715088, '</s>': -2.12...   \n",
       "\n",
       "   generated_overall_log_prob  \\\n",
       "0                   -0.701329   \n",
       "\n",
       "                               class_token_log_probs  \\\n",
       "0  [{'Positive': -6.235310077667236, '</s>': -2.1...   \n",
       "\n",
       "                         class_token_log_probs_total  \n",
       "0  [-6.235331297146331, nan, nan, nan, nan, nan, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472fb13",
   "metadata": {},
   "source": [
    "- `ID` is the datapoint ID\n",
    "\n",
    "- `Target` is the target towards which stance is being inferred\n",
    "\n",
    "- `Tweet` is the tweet to be used to infer stance.\n",
    "\n",
    "- `label` is of the type x--y where x is an indentifier for the prompt_template and y is the identifier for instruction.\n",
    "\n",
    "- `Stance` is the ground truth stance label\n",
    "\n",
    "- `Prompt` is the prompt to the LLM\n",
    "\n",
    "- `class_tokens` refers to the set of candidate tokens (options) for which we compute the probabilities that they are the outputs of the LLM given the prompt, i.e., P(y|x).\n",
    "\n",
    "- **`generated token` is the output by greedy decoding**\n",
    "\n",
    "- `generated_out_tokens_log_prob` is the log probability of the tokens making up the output by greedy decoding\n",
    "\n",
    "- `generated_overall_log_prob` is the total log probability obtained by summing up the tokens making up the output by greedy decoding\n",
    "\n",
    "- `class_token_log_probs` contains the log probabilities of the tokens making up options of interest to us.\n",
    "\n",
    "- `class_token_log_probs_total` is the total log probabilities obtained by summing up the tokens making up the options of interest to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f5949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response to the question should be either positive, negative, or neutral.\n",
      "\n",
      "Statement: \n",
      "Question: What is the attitude of the statement to Atheism?\n"
     ]
    }
   ],
   "source": [
    "print(results_cf.Prompt.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c092791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n"
     ]
    }
   ],
   "source": [
    "# this is the token which flant5-xxl outputs (in a greedy setting)\n",
    "print(results_cf.generated_token.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61550dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neutral': -0.7013075351715088, '</s>': -2.1219479094725102e-05}\n"
     ]
    }
   ],
   "source": [
    "# this is the log probabilities of the answer (generated_token) to the prompt\n",
    "print(results_cf.generated_out_tokens_log_prob.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0faab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7013287546506035\n"
     ]
    }
   ],
   "source": [
    "# this is the sum of the log probabilities of the generated_tokens to the prompt\n",
    "print(results_cf.generated_overall_log_prob.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b76c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'</s>': -2.1219479094725102e-05, 'Positive': -6.235310077667236},\n",
      " {'</s>': nan, 'Neg': -6.172260284423828, 'ative': -19.49579429626465},\n",
      " {'</s>': nan, 'Neu': -5.477845191955566, 'tral': -24.205183029174805},\n",
      " {'.': -12.03813648223877, '</s>': nan, 'Positive': -6.235310077667236},\n",
      " {'.': nan,\n",
      "  '</s>': nan,\n",
      "  'Neg': -6.172260284423828,\n",
      "  'ative': -19.49579429626465},\n",
      " {'.': nan,\n",
      "  '</s>': nan,\n",
      "  'Neu': -5.477845191955566,\n",
      "  'tral': -24.205183029174805},\n",
      " {'</s>': -2.1219479094725102e-05, 'positive': -1.5652083158493042},\n",
      " {'</s>': -2.1219479094725102e-05, 'negative': -1.3100529909133911},\n",
      " {'</s>': -2.1219479094725102e-05, 'neutral': -0.7013075351715088},\n",
      " {'.': -12.03813648223877, '</s>': nan, 'positive': -1.5652083158493042},\n",
      " {'.': -12.03813648223877, '</s>': nan, 'negative': -1.3100529909133911},\n",
      " {'.': -12.03813648223877, '</s>': nan, 'neutral': -0.7013075351715088}]\n"
     ]
    }
   ],
   "source": [
    "# this is the log probabilities of tokens which make up the options in the prompt\n",
    "p.pprint(results_cf.class_token_log_probs.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf74f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.235331297146331,\n",
      " nan,\n",
      " nan,\n",
      " nan,\n",
      " nan,\n",
      " nan,\n",
      " -1.565229535328399,\n",
      " -1.3100742103924858,\n",
      " -0.7013287546506035,\n",
      " nan,\n",
      " nan,\n",
      " nan]\n"
     ]
    }
   ],
   "source": [
    "# this is the sum of the log probabilities of tokens which make up the options in the prompt\n",
    "p.pprint(results_cf.class_token_log_probs_total.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
